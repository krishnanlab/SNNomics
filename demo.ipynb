{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SNNomics demo \n",
    "\n",
    "Problem: There are millions of publicly available transcriptomics samples that can be reused to make novel discoveries about the molecular underpinnings of biological contexts such as tissues, diseases, phenotypes, and molecular pathways. However, only a small fraction of the millions of available samples are annotated to standardized terms denoting biological contexts. Thus, it's difficult to curate large collections of data for researchers to reuse to make discoveries.\n",
    "\n",
    "Solution: To autonomously label transcriptomics samples for which the biological context is unknown, we can use a siamese neural network (SNN) to learn an embedding space that will pull samples derived from the same biological context together and push apart samples from different contexts. To identify samples \n",
    "\n",
    "![Overview](imgs/overview.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83d5c914f0afc17b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import modules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e84d5a66c4b38f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from SNNomics.network import SNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35a03f34657d3d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2623dd7f0df1e88"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query_sample = np.load(\"data/query_sample.npy\")\n",
    "database = np.load(\"data/test_database.npz\")\n",
    "database_expression = database[\"expression\"]\n",
    "database_ids = database['gsms']\n",
    "labels = pd.read_csv('data/tissue_labels.csv', index_col=0)\n",
    "onto_map = pd.read_csv('data/onto_map.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5cab2df0fff6c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define similarity function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef1547ab035ae6af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    dot_product = torch.dot(x, y)\n",
    "    norm_x = torch.norm(x)\n",
    "    norm_y = torch.norm(y)\n",
    "    similarity = dot_product / (norm_x * norm_y)\n",
    "    return similarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e961b8fd268e450e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute similarities between the query and all other samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60a22b98cded1fd9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_genes = len(query_sample)   # Number of genes for input dimension\n",
    "num_samples = len(database_ids) # Number of samples to iterate through\n",
    "model = SNN(num_genes)  # Initialize model\n",
    "\n",
    "query = torch.from_numpy(query_sample)\n",
    "\n",
    "results = {'id': [], 'similarity': []}\n",
    "for sample in range(num_samples):\n",
    "    z = torch.from_numpy(database_expression[sample, :])\n",
    "    query_emb, z_emb = model(query, z)\n",
    "    similarity = cosine_similarity(query_emb, z_emb)\n",
    "    \n",
    "    results['id'].append(database_ids[sample])\n",
    "    results['similarity'].append(similarity.item())\n",
    "    \n",
    "results_df = pd.DataFrame.from_dict(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76895eb49e8f63fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Map tissue labels to samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ba6c39f41aee807"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def assign_labels(gsm: str, labels: pd.DataFrame, onto_map: pd.DataFrame) -> str:\n",
    "    terms = labels.columns[labels.loc[gsm] == 1].tolist()\n",
    "    term_names = []\n",
    "    for term in terms:\n",
    "        term_names.append(onto_map.loc[onto_map['id'] == term, 'name'].item())\n",
    "    \n",
    "    return ','.join(term_names)\n",
    "\n",
    "results_df['tissues'] = results_df['id'].apply(\n",
    "    assign_labels, \n",
    "    labels=labels, \n",
    "    onto_map=onto_map\n",
    ")\n",
    "\n",
    "print(f\"Query tissue: heart\")\n",
    "print(results_df.head(20))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea70974098438f4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
